{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import sys\n",
    "import time\n",
    "from requests.exceptions import SSLError\n",
    "\n",
    "# Matthew's keys\n",
    "noaa_key = \"***REMOVED***\"\n",
    "usda_key = \"***REMOVED***\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is not needed to run the analysis. As of 10/7 the NOAA data is not available due to the effects of the hurricane. We have downlaoded the data and saved it to the folder /data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_usda_data(usda_key, year):\n",
    "  # API endpoint\n",
    "  url = \"https://quickstats.nass.usda.gov/api/api_GET/\"\n",
    "\n",
    "  params = {\n",
    "    \"key\": usda_key,\n",
    "    \"commodity_desc\": \"CORN\",\n",
    "    \"statisticcat_desc\": \"YIELD\",\n",
    "    \"unit_desc\": \"BU / ACRE\",\n",
    "    \"state_alpha\": \"MI\",\n",
    "    \"year\": year,\n",
    "    \"short_desc\": \"CORN, GRAIN - YIELD, MEASURED IN BU / ACRE\",\n",
    "    \"agg_level_desc\": \"COUNTY\",\n",
    "    \"format\": \"JSON\"\n",
    "  }\n",
    "\n",
    "  response = requests.get(url, params=params)\n",
    "\n",
    "  if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    return pd.DataFrame(data['data'])\n",
    "  else:\n",
    "    print(f\"Request failed with status code {response.status_code}\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import requests\n",
    "from requests.exceptions import SSLError\n",
    "\n",
    "def is_valid_data(data):\n",
    "    return data and isinstance(data, dict) and \"results\" in data and data[\"results\"]\n",
    "\n",
    "def get_raw_weather(state_ansi, county_ansi, startdate, enddate):\n",
    "    url = \"https://www.ncdc.noaa.gov/cdo-web/api/v2/data\"\n",
    "    headers = {\n",
    "        'token': noaa_key\n",
    "    }\n",
    "\n",
    "    startdate = pd.to_datetime(startdate)\n",
    "    enddate = pd.to_datetime(enddate)\n",
    "    num_days = (enddate - startdate).days\n",
    "\n",
    "    counties_failed = []\n",
    "\n",
    "    def make_request(params):\n",
    "        retries = 3\n",
    "        backoff = 3\n",
    "        for i in range(retries):\n",
    "            try:\n",
    "                response = requests.get(url, headers=headers, params=params)\n",
    "                if response.status_code == 200:\n",
    "                    data = response.json()\n",
    "                    if is_valid_data(data):\n",
    "                        return pd.DataFrame(data[\"results\"])\n",
    "                    else:\n",
    "                        print(f\"No data found for FIPS:{params['locationid']}\")\n",
    "                        counties_failed.append((params['locationid'], params['startdate'][:4]))  # Append location and year\n",
    "                        return None\n",
    "                elif response.status_code == 429:\n",
    "                    print(f\"Rate limit exceeded. Retrying in {backoff} seconds...\")\n",
    "                    time.sleep(backoff)\n",
    "                    backoff *= 2  # Exponential backoff\n",
    "                elif response.status_code == 503:\n",
    "                    print(\"Server error. Retrying in 3 seconds...\")\n",
    "                    time.sleep(3)\n",
    "                else:\n",
    "                    print(response.text)\n",
    "                    return None\n",
    "            except SSLError as e:\n",
    "                print(f\"SSL Error encountered: {e}. Retrying in 10 seconds...\")\n",
    "                time.sleep(10)\n",
    "        print(f\"Failed to retrieve data after {retries} attempts.\")\n",
    "        counties_failed.append((params['locationid'], params['startdate'][:4]))  # Append location and year\n",
    "        return None\n",
    "\n",
    "    if num_days > 30:\n",
    "        requests_list = []\n",
    "        current_date = startdate\n",
    "        while current_date <= enddate:\n",
    "            current_enddate = current_date + pd.DateOffset(days=30)\n",
    "            if current_enddate > enddate:\n",
    "                current_enddate = enddate\n",
    "\n",
    "            params = {\n",
    "                \"datasetid\": \"GHCND\",\n",
    "                \"startdate\": current_date.strftime(\"%Y-%m-%d\"),\n",
    "                \"enddate\": current_enddate.strftime(\"%Y-%m-%d\"),\n",
    "                \"units\": \"standard\",\n",
    "                \"limit\": \"1000\",\n",
    "                \"locationid\": f\"FIPS:{state_ansi}{county_ansi}\",\n",
    "                'datatypeid': ['TMAX', 'TMIN', \"PRCP\"]\n",
    "            }\n",
    "\n",
    "            print(f\"FIPS:{state_ansi}{county_ansi}\")\n",
    "            result = make_request(params)\n",
    "            if result is not None:\n",
    "                requests_list.append(result)\n",
    "\n",
    "            current_date = current_enddate + pd.DateOffset(days=1)\n",
    "\n",
    "        if requests_list:\n",
    "            final_result = pd.concat(requests_list)\n",
    "        else:\n",
    "            final_result = None\n",
    "    else:\n",
    "        params = {\n",
    "            \"datasetid\": \"GHCND\",\n",
    "            \"startdate\": startdate.strftime(\"%Y-%m-%d\"),\n",
    "            \"enddate\": enddate.strftime(\"%Y-%m-%d\"),\n",
    "            \"units\": \"standard\",\n",
    "            \"limit\": \"1000\",\n",
    "            \"locationid\": f\"FIPS:{state_ansi}{county_ansi}\",\n",
    "            'datatypeid': ['TMAX', 'TMIN', \"PRCP\"]\n",
    "        }\n",
    "\n",
    "        print(f\"FIPS:{state_ansi}{county_ansi}\")\n",
    "        final_result = make_request(params)\n",
    "\n",
    "    # At the end of the process, append counties and year to a file if there are any\n",
    "    if counties_failed:\n",
    "        with open('counties_failed.txt', 'a') as file:  # Open in append mode\n",
    "            for county, year in counties_failed:  # Unpack the tuple\n",
    "                file.write(f\"{county}, {year}\\n\")\n",
    "        print(\"Counties with no data have been appended to 'counties_failed.txt'.\")\n",
    "\n",
    "    return final_result\n",
    "\n",
    "# Usage\n",
    "# df = get_raw_weather(state_ansi, county_ansi, \"2023-01-01\", \"2023-01-31\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_weather(df,state_ansi,county_ansi):\n",
    "    # For each day in date column average the TMAX and TMIN into their own columns across all stations\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "    df[\"TMAX\"] = df[\"value\"].where(df[\"datatype\"] == \"TMAX\")\n",
    "    df[\"TMIN\"] = df[\"value\"].where(df[\"datatype\"] == \"TMIN\")\n",
    "    df[\"PRCP\"] = df[\"value\"].where(df[\"datatype\"] == \"PRCP\")\n",
    "    \n",
    "    df = df.groupby(\"date\").agg({\"TMAX\": \"mean\", \"TMIN\": \"mean\", \"PRCP\": \"mean\"}).reset_index()\n",
    "\n",
    "    # add state and county columns\n",
    "    df[\"state_ansi\"] = state_ansi\n",
    "    df[\"county_ansi\"] = county_ansi\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each state_ansi county_ansi combo in the USDA data, get the weather data\n",
    "\n",
    "def get_weather_data(usda_df,year):\n",
    "    weather_data = []\n",
    "    for index, row in usda_df.iterrows():\n",
    "        state_ansi = row[\"state_ansi\"]\n",
    "        county_ansi = row[\"county_ansi\"]\n",
    "        #time.sleep(1)\n",
    "        weather_raw = get_raw_weather(state_ansi, county_ansi, f\"{year}-05-15T00:00:00\", f\"{year}-10-15T00:00:00\")\n",
    "        if weather_raw is not None:\n",
    "            weather = clean_weather(weather_raw, state_ansi, county_ansi)\n",
    "            weather_data.append(weather)\n",
    "    return pd.concat(weather_data)\n",
    "\n",
    "# weather_data = get_weather_data(usda_df)\n",
    "# weather_data.to_csv(\"weather_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = range(1995, 2013)\n",
    "\n",
    "\n",
    "for year in years:\n",
    "  print(year)\n",
    "  usda_data = get_usda_data(usda_key, year)\n",
    "  usda_data.to_csv(f\"data/usda_data_{year}.csv\", index=False)\n",
    "  weather_data=get_weather_data(usda_data,year)\n",
    "  weather_data.to_csv(f\"data/weather_data_{year}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
