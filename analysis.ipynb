{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.stats import linregress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis**\n",
    "------------\n",
    "In this section we start the core of our analysis separate from discovery. While the discovery section is more about finding out what is in the data, the analysis section is about what we can do with the data. We start back again with our raw data and look to try and arrive at some conclusions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all weather data into a single DataFrame\n",
    "weather_data = pd.concat([pd.read_csv(f'data/weather_data_{year}.csv') for year in range(1950, 2024)])\n",
    "# Calculate GDD for each day\n",
    "weather_data = calculate_gdd(weather_data)\n",
    "weather_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the analysis, a function is created that we can send a usda dataframe, provide the start and end dates, and determine whether or not we want to include \"other counties\". I will focus on year, county_name, county_ansi, and Value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'date' to datetime if it's not already\n",
    "weather_data['date'] = pd.to_datetime(weather_data['date'])\n",
    "\n",
    "# Extract year and month\n",
    "weather_data['year'] = weather_data['date'].dt.year\n",
    "weather_data['month'] = weather_data['date'].dt.month\n",
    "\n",
    "# Aggregate GDD by county and year\n",
    "gdd_annual = weather_data.groupby(['state_ansi', 'county_ansi', 'year'])['GDD'].sum().reset_index()\n",
    "gdd_annual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all USDA data into a single DataFrame usda_data\n",
    "usda_data = pd.concat([pd.read_csv(f'data/usda_data_{year}.csv') for year in range(1950, 2024)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I added some lines to clean the data, most files are fine but I am looking for the 'YIELD' data and skipping any suppressed data\n",
    "\n",
    "# Filter for the relevant data (e.g., 'YIELD' in 'statisticcat_desc')\n",
    "corn_data = usda_data[usda_data['statisticcat_desc'] == 'YIELD']\n",
    "\n",
    "# Convert 'Value' to numeric, removing any commas or missing values\n",
    "corn_data['Value'] = corn_data['Value'].replace(',', '', regex=True)\n",
    "corn_data = corn_data[corn_data['Value'] != '(D)']  # Remove suppressed data\n",
    "corn_data['Value'] = pd.to_numeric(corn_data['Value'])\n",
    "\n",
    "# Select relevant columns\n",
    "corn_data = corn_data[['state_ansi', 'county_ansi', 'year', 'Value', 'county_name']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the GDD and corn yield data to make a single DataFrame\n",
    "\n",
    "# Merge on 'state_ansi', 'county_ansi', and 'year'\n",
    "merged_data = pd.merge(gdd_annual, corn_data, on=['state_ansi', 'county_ansi', 'year'])\n",
    "# Remove entries with zero or NaN yields\n",
    "merged_data = merged_data[merged_data['Value'] > 0]\n",
    "# Remove entries with zero or NaN yields\n",
    "merged_data = merged_data[merged_data['GDD'] > 0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data['Value'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data['GDD'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualize Data Distribution**\n",
    "-------------------------------\n",
    "Plot boxplots to visualize the distribution of GDD and corn yield."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with subplots for side-by-side comparison\n",
    "fig, axs = plt.subplots(1, 2, figsize=(14, 7))\n",
    "\n",
    "# Plot for 'GDD'\n",
    "axs[0].boxplot(merged_data['GDD'], patch_artist=True,\n",
    "               boxprops=dict(facecolor='skyblue', color='blue'),\n",
    "               flierprops=dict(marker='o', markerfacecolor='red', markersize=8, linestyle='none'),\n",
    "               medianprops=dict(color='orange', linewidth=2))\n",
    "axs[0].set_title('Corn Growing Degree Days (GDD)', fontsize=14)\n",
    "axs[0].set_ylabel('GDD', fontsize=12)\n",
    "axs[0].set_xlabel('Corn Growing Degree Days (GDD)', fontsize=12)\n",
    "axs[0].grid(True)\n",
    "\n",
    "# Overlay data points\n",
    "axs[0].scatter(np.ones(len(merged_data['GDD'])), merged_data['GDD'], color='black', alpha=0.5)\n",
    "\n",
    "# Plot for Corn\n",
    "axs[1].boxplot(merged_data['Value'], patch_artist=True,\n",
    "               boxprops=dict(facecolor='lightgreen', color='green'),\n",
    "               flierprops=dict(marker='o', markerfacecolor='red', markersize=8, linestyle='none'),\n",
    "               medianprops=dict(color='orange', linewidth=2))\n",
    "axs[1].set_title('Corn Yield', fontsize=14)\n",
    "axs[1].set_ylabel('Corn Yield', fontsize=12)\n",
    "axs[1].set_xlabel('Corn Yield', fontsize=12)\n",
    "axs[1].grid(True)\n",
    "\n",
    "# Overlay data points\n",
    "axs[1].scatter(np.ones(len(merged_data['Value'])), merged_data['Value'], color='black', alpha=0.5)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remove Outliers**\n",
    "-------------------\n",
    "Identify and remove outliers using the Interquartile Range (IQR) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate IQR for 'GDD' and 'Value' columns to identify outliers\n",
    "Q1_GDD = merged_data['GDD'].quantile(0.25)\n",
    "Q3_GDD = merged_data['GDD'].quantile(0.75)\n",
    "IQR_GDD = Q3_GDD - Q1_GDD\n",
    "\n",
    "Q1_Value = merged_data['Value'].quantile(0.25)\n",
    "Q3_Value = merged_data['Value'].quantile(0.75)\n",
    "IQR_Value = Q3_Value - Q1_Value\n",
    "\n",
    "# Define bounds for outliers in 'GDD' and 'Value'\n",
    "lower_bound_GDD = Q1_GDD - 1.5 * IQR_GDD\n",
    "upper_bound_GDD = Q3_GDD + 1.5 * IQR_GDD\n",
    "\n",
    "lower_bound_Value = Q1_Value - 1.5 * IQR_Value\n",
    "upper_bound_Value = Q3_Value + 1.5 * IQR_Value\n",
    "\n",
    "# Filter out the outliers\n",
    "merged_data = merged_data[\n",
    "    (merged_data['GDD'] >= lower_bound_GDD) & (merged_data['GDD'] <= upper_bound_GDD) &\n",
    "    (merged_data['Value'] >= lower_bound_Value) & (merged_data['Value'] <= upper_bound_Value)\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Re-examine the Data**\n",
    "-----------------------\n",
    "Check the statistical summary after removing outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data['Value'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data['GDD'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump merged_data to csv for sanity check\n",
    "merged_data.to_csv('merged_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualize Correlation Between GDD and Corn Yield**\n",
    "----------------------------------------------------\n",
    "Create a scatter plot to visualize the correlation, with a color gradient showing time progression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatter plot with color gradient for time progression\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Scatter plot with color mapped to 'year' and a plasma colormap for better color representation\n",
    "scatter = plt.scatter(x=merged_data['GDD'], y=merged_data['Value'], c=merged_data['year'], cmap='plasma', s=10)\n",
    "\n",
    "# Add colorbar to show year progression\n",
    "cbar = plt.colorbar(scatter)\n",
    "cbar.set_label('Year')\n",
    "\n",
    "# Set titles and labels\n",
    "plt.title('Correlation between GDD and Corn Yield with Time Progression', fontsize=14)\n",
    "plt.xlabel('Growing Degree Days (GDD)', fontsize=12)\n",
    "plt.ylabel('Corn Yield (bu/acre)', fontsize=12)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot of GDD vs. corn yield\n",
    "sns.lmplot(x='GDD', y='Value', data=merged_data, scatter_kws={'s': 1})\n",
    "plt.title('Correlation between GDD and Corn Yield')\n",
    "plt.xlabel('Growing Degree Days (GDD)')\n",
    "plt.ylabel('Corn Yield (bu/acre)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analyze Precipitation Data**\n",
    "------------------------------\n",
    "We will analyze the correlation between total precipitation (PRCP) and corn yield."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the same chart with PRCP instead of GDD\n",
    "\n",
    "# Calculate total precipitation for the growing season\n",
    "weather_data['PRCP'] = weather_data['PRCP'].clip(lower=0)\n",
    "prcp_annual = weather_data.groupby(['state_ansi', 'county_ansi', 'year'])['PRCP'].sum().reset_index()\n",
    "\n",
    "# Merge on 'state_ansi', 'county_ansi', and 'year'\n",
    "merged_data_prcp = pd.merge(prcp_annual, corn_data, on=['state_ansi', 'county_ansi', 'year'])\n",
    "# Remove entries with zero or NaN yields\n",
    "merged_data_prcp = merged_data_prcp[merged_data_prcp['Value'] > 0]\n",
    "# Remove entries with zero or NaN yields\n",
    "merged_data_prcp = merged_data_prcp[merged_data_prcp['PRCP'] > 0]\n",
    "\n",
    "# Scatter plot with regression line\n",
    "sns.lmplot(x='PRCP', y='Value', data=merged_data_prcp, scatter_kws={'s': 0.5})\n",
    "plt.title('Correlation between PRCP and Corn Yield')\n",
    "plt.xlabel('Total Precipitation (mm)')\n",
    "plt.ylabel('Corn Yield (bu/acre)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the data was similar to the GDD data, we dind't feel it was necessary to include the analysis of the precipitation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add precipitation data to the merged dataframe\n",
    "#prcp_annual = weather_data.groupby(['state_ansi', 'county_ansi', 'year'])['PRCP'].sum().reset_index()\n",
    "#merged_data = pd.merge(merged_data, prcp_annual, on=['state_ansi', 'county_ansi', 'year'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Perform Linear Regression Analysis**\n",
    "--------------------------------------\n",
    "We will perform an Ordinary Least Squares (OLS) regression to quantify the relationship between GDD and corn yield."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Prepare the data for OLS (adding a constant for intercept)\n",
    "X = sm.add_constant(merged_data['GDD'])  # Independent variable (GDD) with a constant\n",
    "y = merged_data['Value']  # Dependent variable (Corn Yield)\n",
    "\n",
    "# Step 2: Fit the OLS model\n",
    "ols_model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Step 3: Print out the summary of the regression\n",
    "print(ols_model.summary())\n",
    "\n",
    "# Step 4: Plot the scatter plot with regression line (optional, already in your code)\n",
    "sns.lmplot(x='GDD', y='Value', data=merged_data, scatter_kws={'s': 1})\n",
    "plt.title('Correlation between GDD and Corn Yield')\n",
    "plt.xlabel('Growing Degree Days (GDD)')\n",
    "plt.ylabel('Corn Yield (bu/acre)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Multiple Linear Regression**\n",
    "------------------------------\n",
    "Include both GDD and Year as independent variables to see if time has an effect on yield."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Prepare the data for OLS (adding a constant for intercept)\n",
    "X = merged_data[['GDD', 'year']]  # Independent variables (GDD and Year)\n",
    "X = sm.add_constant(X)  # Add constant for the intercept\n",
    "y = merged_data['Value']  # Dependent variable (Corn Yield)\n",
    "\n",
    "# Step 2: Fit the OLS model\n",
    "ols_model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Step 3: Print out the summary of the regression\n",
    "print(ols_model.summary())\n",
    "\n",
    "# Step 4: Plot the scatter plot with regression line for GDD (optional)\n",
    "sns.lmplot(x='GDD', y='Value', data=merged_data, scatter_kws={'s': 1})\n",
    "plt.title('Correlation between GDD and Corn Yield')\n",
    "plt.xlabel('Growing Degree Days (GDD)')\n",
    "plt.ylabel('Corn Yield (bu/acre)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define independent variables and dependent variable\n",
    "#X = merged_data[['GDD', 'PRCP']]\n",
    "X = merged_data[['Value']]\n",
    "y = merged_data['GDD']\n",
    "\n",
    "# Add a constant term for the intercept\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the regression model\n",
    "model = sm.OLS(y, X).fit()\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ranking**\n",
    "------------\n",
    "We determined a ranking of the counties based on a number of factors and will use a normalized score to rank the counties. in the end.\n",
    "\n",
    "- Highest Average Yield\n",
    "- Consistency Above State Average\n",
    "- Highest GDD\n",
    "- Low Variability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average yield per county over the entire period\n",
    "average_yield = merged_data.groupby('county_name')['Value'].mean().reset_index()\n",
    "\n",
    "# Sort counties by average yield in descending order\n",
    "average_yield_sorted = average_yield.sort_values(by='Value', ascending=False)\n",
    "\n",
    "# Top 10 counties\n",
    "print(\"Top 10 Counties by Average Corn Yield:\")\n",
    "print(average_yield_sorted.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Horizontal bar plot of average yields for top 10 counties in reverse order\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.barh(average_yield_sorted['county_name'].head(10)[::-1], average_yield_sorted['Value'].head(10)[::-1], color='skyblue')\n",
    "plt.ylabel('County')\n",
    "plt.xlabel('Average Corn Yield (bu/acre)')\n",
    "plt.title('Top 10 Counties by Average Corn Yield')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I was wondering if we pick the best based how consistent are they in beating the state average\n",
    "\n",
    "# Calculate the state average yield for each year\n",
    "state_average_yield = merged_data.groupby('year')['Value'].mean().reset_index(name='state_avg_yield')\n",
    "\n",
    "# Merge state average back into merged_data\n",
    "merged_data_with_state_avg = pd.merge(merged_data, state_average_yield, on='year')\n",
    "\n",
    "# Create a flag for whether the county's yield is above the state average each year\n",
    "merged_data_with_state_avg['above_state_avg'] = merged_data_with_state_avg['Value'] > merged_data_with_state_avg['state_avg_yield']\n",
    "\n",
    "# Calculate the percentage of years each county was above the state average\n",
    "county_performance = merged_data_with_state_avg.groupby('county_name')['above_state_avg'].mean().reset_index()\n",
    "\n",
    "# Convert to percentage\n",
    "county_performance['percent_above_state_avg'] = county_performance['above_state_avg'] * 100\n",
    "\n",
    "# Sort counties by percentage in descending order\n",
    "county_performance_sorted = county_performance.sort_values(by='percent_above_state_avg', ascending=False)\n",
    "\n",
    "# Display the top 10 counties\n",
    "print(\"Top 10 Counties by Consistency in Exceeding State Average Yield:\")\n",
    "print(county_performance_sorted.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Horizontal bar plot of top 10 counties by percentage of years above state average in reverse order\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.barh(county_performance_sorted['county_name'].head(10)[::-1], county_performance_sorted['percent_above_state_avg'].head(10)[::-1], color='orange')\n",
    "plt.ylabel('County')\n",
    "plt.xlabel('Percentage of Years Above State Average (%)')\n",
    "plt.title('Top 10 Counties Consistently Exceeding State Average Yield')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What about finding the best improved county over time wiht slope\n",
    "\n",
    "# Prepare a DataFrame to store slopes\n",
    "county_slopes = []\n",
    "\n",
    "for county in merged_data['county_name'].unique():\n",
    "    county_data = merged_data[merged_data['county_name'] == county]\n",
    "    if len(county_data['year'].unique()) > 1:  # Ensure there's enough data\n",
    "        slope, intercept, r_value, p_value, std_err = linregress(county_data['year'], county_data['Value'])\n",
    "        county_slopes.append({'county_name': county, 'slope': slope, 'p_value': p_value})\n",
    "    else:\n",
    "        county_slopes.append({'county_name': county, 'slope': np.nan, 'p_value': np.nan})\n",
    "\n",
    "# Convert to DataFrame\n",
    "slopes_df = pd.DataFrame(county_slopes)\n",
    "\n",
    "# Remove counties with NaN slopes\n",
    "slopes_df.dropna(subset=['slope'], inplace=True)\n",
    "\n",
    "# Sort counties by slope\n",
    "slopes_df_sorted = slopes_df.sort_values(by='slope', ascending=False)\n",
    "\n",
    "print(\"Top 10 Counties by Yield Improvement Over Time:\")\n",
    "print(slopes_df_sorted.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Horizontal bar plot of top 10 counties by yield improvement over time (slope)\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.barh(slopes_df_sorted['county_name'].head(10)[::-1], slopes_df_sorted['slope'].head(10)[::-1], color='green')\n",
    "plt.ylabel('County')\n",
    "plt.xlabel('Slope of Yield Improvement Over Time')\n",
    "plt.title('Top 10 Counties by Yield Improvement Over Time')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets looks at the counties that have been the most consistent in their yield over time\n",
    "\n",
    "# Calculate standard deviation of yield per county\n",
    "yield_variability = merged_data.groupby('county_name')['Value'].std().reset_index(name='yield_std')\n",
    "\n",
    "# Sort counties by yield_std in ascending order\n",
    "yield_variability_sorted = yield_variability.sort_values(by='yield_std')\n",
    "\n",
    "print(\"Top 10 Counties with Least Yield Variability:\")\n",
    "print(yield_variability_sorted.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Horizontal bar plot of top 10 counties with least yield variability (standard deviation)\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.barh(yield_variability_sorted['county_name'].head(10)[::-1], yield_variability_sorted['yield_std'].head(10)[::-1], color='purple')\n",
    "plt.ylabel('County')\n",
    "plt.xlabel('Yield Variability (Standard Deviation)')\n",
    "plt.title('Top 10 Counties with Least Yield Variability (Reversed Order)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets look at the counties with the highest average gdd\n",
    "\n",
    "# Calculate average GDD per county\n",
    "avg_gdd_per_county = merged_data.groupby('county_name')['GDD'].mean().reset_index()\n",
    "\n",
    "# Sort counties by average GDD in descending order\n",
    "avg_gdd_per_county_sorted = avg_gdd_per_county.sort_values(by='GDD', ascending=False)\n",
    "\n",
    "print(\"Top 10 Counties by Average Growing Degree Days:\")\n",
    "print(avg_gdd_per_county_sorted.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Horizontal bar plot of top 10 counties by average GDD\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.barh(avg_gdd_per_county_sorted['county_name'].head(10)[::-1], avg_gdd_per_county_sorted['GDD'].head(10)[::-1], color='red')\n",
    "plt.ylabel('County')\n",
    "plt.xlabel('Average Growing Degree Days (GDD)')\n",
    "plt.title('Top 10 Counties by Average Growing Degree Days')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use county_name to merge all the other DFs\n",
    "county_metrics = average_yield[['county_name', 'Value']].merge(\n",
    "    county_performance[['county_name', 'percent_above_state_avg']], on='county_name').merge(\n",
    "    yield_variability[['county_name', 'yield_std']], on='county_name').merge(\n",
    "    avg_gdd_per_county[['county_name', 'GDD']], on='county_name')\n",
    "\n",
    "# Normalize the metrics\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "county_metrics[['avg_yield_norm', 'percent_above_avg_norm', 'yield_std_norm', 'avg_gdd_per_county']] = scaler.fit_transform(\n",
    "    county_metrics[['Value', 'percent_above_state_avg', 'yield_std', 'GDD']])\n",
    "\n",
    "# Invert yield_std_norm so that lower variability scores higher\n",
    "county_metrics['yield_std_norm'] = 1 - county_metrics['yield_std_norm']\n",
    "\n",
    "# I assigned weights to each metric but nothing scientific\n",
    "# Should come back to this later\n",
    "county_metrics['total_score'] = (\n",
    "    county_metrics['avg_yield_norm'] * 0.4 +\n",
    "    county_metrics['percent_above_avg_norm'] * 0.3 +\n",
    "    county_metrics['yield_std_norm'] * 0.1 +\n",
    "    county_metrics['avg_gdd_per_county'] * 0.1\n",
    ")\n",
    "\n",
    "# Sort counties by total_score\n",
    "county_metrics_sorted = county_metrics.sort_values(by='total_score', ascending=False)\n",
    "\n",
    "print(\"Top 10 Counties by Composite Score:\")\n",
    "print(county_metrics_sorted[['county_name', 'total_score']].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot of top 10 counties by composite score\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(county_metrics_sorted['county_name'].head(10), county_metrics_sorted['total_score'].head(10), color='purple')\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel('County')\n",
    "plt.ylabel('Composite Score')\n",
    "plt.title('Top 10 Counties by Composite Score')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for heatmap\n",
    "metrics_for_heatmap = county_metrics_sorted[['county_name', 'avg_yield_norm', 'percent_above_avg_norm', 'yield_std_norm', 'avg_gdd_per_county', 'total_score']].set_index('county_name')\n",
    "\n",
    "# Rename the columns to make the metric names more readable\n",
    "metrics_for_heatmap.rename(columns={\n",
    "    'avg_yield_norm': 'Normalized Avg Yield',\n",
    "    'percent_above_avg_norm': 'Percent Years Above Avg Yield',\n",
    "    'yield_std_norm': 'Normalized Yield Variability',\n",
    "    'avg_gdd_per_county': 'Avg Growing Degree Days (GDD)',\n",
    "    'total_score': 'Total Score'\n",
    "}, inplace=True)\n",
    "\n",
    "# Set a larger and professional style\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Plot heatmap with enhancements\n",
    "heatmap = sns.heatmap(metrics_for_heatmap.head(10), \n",
    "                      annot=True, \n",
    "                      cmap='coolwarm',  # More polished colormap\n",
    "                      linewidths=0.5,   # Add gridlines\n",
    "                      linecolor='black', # Gridline color\n",
    "                      annot_kws={\"size\": 10},  # Annotation text size\n",
    "                      cbar_kws={'label': 'Normalized Values'})  # Label the color bar\n",
    "\n",
    "# Enhance title and axis labels\n",
    "plt.title('Normalized Metrics and Total Score for Top 10 Counties', fontsize=16, weight='bold', pad=20)\n",
    "plt.xlabel('Metrics', fontsize=12)\n",
    "plt.ylabel('County', fontsize=12)\n",
    "\n",
    "# Add a descriptive legend for x-axis values\n",
    "plt.figtext(0.46, -0.1,\n",
    "            'Normalized Avg Yield: Normalized average corn yield per county\\n'\n",
    "            'Percent Years Above Avg Yield: Percent of years the county yield exceeded the state average\\n'\n",
    "            'Normalized Yield Variability: Lower values indicate more consistent yields\\n'\n",
    "            'Avg Growing Degree Days (GDD): Average GDD needed for corn production\\n'\n",
    "            'Total Score: Composite score from the weighted sum of all metrics',\n",
    "            ha='center', fontsize=10, wrap=True, bbox={\"facecolor\":\"lightgray\", \"alpha\":0.5, \"pad\":5})\n",
    "\n",
    "# Adjust layout for better spacing\n",
    "plt.xticks(rotation=30, ha='right', fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the heatmap\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
