{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.stats import linregress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discovery**\n",
    "-------------\n",
    "Discovery is the exploratory phase of the data analysis. Learning how to cleanse the data to produce meaningful results during analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all the data/usda_* into one dataframe\n",
    "usda = pd.concat([pd.read_csv(f'data/usda_data_{year}.csv')  for year in range(1950, 2024)])\n",
    "\n",
    "# combine all the data/weather_* into one dataframe\n",
    "weather = pd.concat([pd.read_csv(f'data/weather_data_{year}.csv') for year in range(1950, 2024)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usda.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the average value in udsa data for each year\n",
    "usda.groupby('year')['Value'].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the average value in udsa data for each year\n",
    "usda.groupby('year')['Value'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting the columns needed for analysis (year, county_name, county_ansi and Value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "usda['year'] = pd.to_datetime(usda['year'],\n",
    "               format='%Y')\n",
    "usda_subset = usda[['year','county_name','county_ansi','Value']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usda_subset['county_name'].nunique() #85 Michigan has 83"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is that the data set has 85 and Michigan only has 83. The additional two are 'OTHER COUNTIES' and 'OTHER (COMBINED) COUNTIES'.\n",
    "what do the entries look like for 'OTHER (COMBINED) COUNTIES'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usda_subset_other_combined = usda_subset[usda_subset['county_name'] == 'OTHER (COMBINED) COUNTIES']\n",
    "usda_subset_other_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 144 records that contain 'OTHER (COMBINED) COUNTIES' and three entries for 1960 and several entries for 2019. It appears that perhaps the \"Other Counties\" was a dumping ground for smaller quanities collected over several counties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 3 entries for 1960 have the following asd_desc: \"UPPER PENINSULA\", \"NORTHWEST\", and \"NORTHEAST\". The location_desc has these entries: \"MICHIGAN, UPPER PENINSULA, OTHER (COMBINED) COUNTIES\", \"MICHIGAN, NORTHWEST, OTHER (COMBINED) COUNTIES\", and \"MICHIGAN, NORTHEAST, OTHER (COMBINED) COUNTIES\". How many bushels/acre were reported total?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)\n",
    "usda_subset_1960 = usda[(usda['year'] == '1960-01-01') & usda['county_name'].str.upper().str.contains('OTHER')]\n",
    "usda_subset_1960"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usda_subset_1960.groupby('county_name')['Value'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total Value for 1960 \"OTHER (COMBINED) COUNTIES\" was 130.6\n",
    "A similiar dumping ground value when compared to the single \"OTHER COUNTIES\" in 2020.\n",
    "\n",
    "2019 seemed to have a lot of entries for \"OTHER (COMBINED) COUNTIES\". What is going on?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usda_2019 = usda[(usda['year'] == '2019-01-01') & (usda['county_name'] == 'OTHER (COMBINED) COUNTIES')]\n",
    "usda_2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 7 entries for 2019 have the following asd_desc: \"UPPER PENINSULA\", \"NORTHWEST\", \"NORTHEAST\",\"WEST CENTRAL\", \"CENTRAL\", \"SOUTHWEST\", and \"SOUTH CENTRAL\". The location_desc has these entries: \"MICHIGAN, UPPER PENINSULA, OTHER (COMBINED) COUNTIES\", \"MICHIGAN, NORTHWEST, OTHER (COMBINED) COUNTIES\", \"MICHIGAN, NORTHEAST, OTHER (COMBINED) COUNTIES\",\"MICHIGAN, WEST CENTRAL, OTHER (COMBINED) COUNTIES\", \"MICHIGAN, CENTRAL, OTHER (COMBINED) COUNTIES\", \"MICHIGAN, SOUTHWEST, OTHER (COMBINED) COUNTIES\", and \"MICHIGAN, SOUTH CENTRAL, OTHER (COMBINED) COUNTIES\".\n",
    "\n",
    "How many years and how many entries are we looking at that are like this? It looks like 2019 was the worst with 7 regions identified. The amount of bushels/acre is  886.3. This is considerably more than 1960."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = usda.groupby(['year', 'county_name']).agg(\n",
    "    count=('county_name', 'count'),\n",
    "    sum=('Value', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "filtered_df = grouped_df[grouped_df['count'] > 1]\n",
    "# Sort by 'sum' in descending order\n",
    "filtered_df = filtered_df.sort_values(by='sum', ascending=False)\n",
    "\n",
    "print(filtered_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When comparing to the rest of the entries in 2019. How bad does it look?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "usda_subset_2019=usda_subset[usda_subset['year'] == '2019-01-01']\n",
    "grouped_df_2019 = usda_subset_2019.groupby(['year', 'county_name']).agg(\n",
    "    count=('county_name', 'count'),\n",
    "    sum=('Value', 'sum')\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust figure size for better readability\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Create the scatter plot\n",
    "g = sns.scatterplot(data=grouped_df_2019, x=\"county_name\", y=\"sum\", hue=\"year\")\n",
    "\n",
    "# Rotate the x-axis labels for readability\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Counties')\n",
    "plt.ylabel('BU/Acre')\n",
    "plt.title('Bushels/Acre by County for 2019')\n",
    "\n",
    "# Adjust the legend positioning\n",
    "#g.legend(loc='center left', bbox_to_anchor=(1.25, 0.5), ncol=1)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest of the counties for 2019 produced no more than 200 bushels/acre. As expected, \"OTHER (COMBINED) COUNTIES\" is the highest in the chart. What about those single entries for 'OTHER COUNTIES' after 2020?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usda_subset_other = usda_subset[usda_subset['county_name'] == 'OTHER COUNTIES']\n",
    "usda_subset_other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 4 records (years) that contain 'OTHER COUNTIES'; no duplicated years. We will go back to the original dataset and look at the entire record for those years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)\n",
    "usda_other = usda[usda['county_name'] == 'OTHER COUNTIES']\n",
    "usda_other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The asd_desc and location_desc is null for all 4 records is \"MICHIGAN, OTHER COUNTIES\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will take a look and see how many total counties are reporting beyond 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame for the year >= 2020\n",
    "usda_subset = usda[usda['year'] >= '2020']\n",
    "\n",
    "# Count the number of unique county names by year\n",
    "unique_counties_by_year = usda_subset.groupby('year')['county_name'].nunique()\n",
    "unique_counties_by_year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 61 counties in the data set for 2020. And those unique counties are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame for the year >= 2020\n",
    "usda_subset_2020 = usda_subset[usda_subset['year'] == '2020']\n",
    "usda_subset_2020['county_name'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "array(['DELTA', 'DICKINSON', 'MENOMINEE', 'ANTRIM', 'BENZIE',\n",
    "       'CHARLEVOIX', 'EMMET', 'GRAND TRAVERSE', 'LEELANAU', 'MANISTEE',\n",
    "       'WEXFORD', 'ALCONA', 'ALPENA', 'IOSCO', 'OGEMAW', 'OTSEGO',\n",
    "       'PRESQUE ISLE', 'MASON', 'MUSKEGON', 'NEWAYGO', 'OCEANA',\n",
    "       'GLADWIN', 'ISABELLA', 'MECOSTA', 'MIDLAND', 'MONTCALM', 'ARENAC',\n",
    "       'BAY', 'HURON', 'SAGINAW', 'SANILAC', 'TUSCOLA', 'ALLEGAN',\n",
    "       'BERRIEN', 'CASS', 'KALAMAZOO', 'KENT', 'OTTAWA', 'VAN BUREN',\n",
    "       'BARRY', 'BRANCH', 'CALHOUN', 'CLINTON', 'EATON', 'HILLSDALE',\n",
    "       'INGHAM', 'IONIA', 'JACKSON', 'ST JOSEPH', 'SHIAWASSEE', 'GENESEE',\n",
    "       'LAPEER', 'LENAWEE', 'LIVINGSTON', 'MACOMB', 'MONROE', 'OAKLAND',\n",
    "       'ST CLAIR', 'WASHTENAW', 'WAYNE', 'OTHER COUNTIES'], dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the average value in udsa data for each of those years\n",
    "mean_value = usda_subset.groupby('year')['Value'].mean()\n",
    "\n",
    "# create other Dataframe from orignial data\n",
    "usda_other = usda[usda['county_name'] == 'OTHER COUNTIES']\n",
    "usda_other\n",
    "\n",
    "# Merge the two DataFrames for comparison\n",
    "comparison = pd.merge(mean_value, usda_other, on='year', how='outer')\n",
    "\n",
    "# Rename columns for clarity\n",
    "comparison.rename(columns={'Value_x': 'Yearly Mean', 'Value_y':'Value'}, inplace=True)\n",
    "\n",
    "# Calculate the difference\n",
    "comparison['Difference'] = comparison['Yearly Mean'] - comparison['Value']\n",
    "comparison[['year','Yearly Mean', 'Value', 'Difference']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference is no greater than 14.7 bushels per acre. This is not significant when compared to the mean for each year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's do the same for the \"OTHER (COMBINED)\" years. They stopped using that in 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame for the year <= 2019\n",
    "usda_subset_other_combined = usda[usda['year'] <= '2019']\n",
    "\n",
    "# what is the average value in udsa data for each of those years\n",
    "mean_value = usda_subset_other_combined.groupby('year')['Value'].mean()\n",
    "\n",
    "# Filter for counties where 'county_name' contains 'OTHER (COMBINED)' (case insensitive)\n",
    "other_combined = usda_subset_other_combined[usda_subset_other_combined['county_name'].str.contains('OTHER \\(COMBINED\\)', case=False, regex=True)]\n",
    "\n",
    "# Sum the 'Value' for OTHER (COMBINED) COUNTIES\n",
    "other_combined_sum = other_combined.groupby('year')['Value'].sum().reset_index('year')\n",
    "\n",
    "# Merge the two DataFrames for comparison and drop the records where there weren't \"Other (Combined)\" Counties\n",
    "comparison = pd.merge(mean_value, other_combined_sum, on='year', how='outer').dropna()\n",
    "\n",
    "# Rename columns for clarity\n",
    "comparison.rename(columns={'Value_x': 'Yearly Mean', 'Value_y':'Other Total Value'}, inplace=True)\n",
    "\n",
    "# Calculate the difference\n",
    "comparison['Difference'] = comparison['Yearly Mean'] - comparison['Other Total Value']\n",
    "comparison[['year','Yearly Mean', 'Other Total Value', 'Difference']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the figure size\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot the yearly mean and total value for \"Other Combined\" counties\n",
    "sns.lineplot(x='year', y='Yearly Mean', data=comparison, label='Yearly Mean')\n",
    "sns.lineplot(x='year', y='Other Total Value', data=comparison, label='Other Total Value')\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Yearly Mean vs. Other Combined Counties Total Value')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average value across counties does not change much over time, remaining stable even as the data for \"Other Combined\" counties fluctuates. The Other total value has several sharp spikes, with rapid increases and decreases.\n",
    "\n",
    "Now that we understand how to cleanse the usda data, we will create a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_usda(usda_df, start_year, end_year, other='Yes'):\n",
    "    # We will focus the fields from the dataframe we are interested in\n",
    "    filtered_df = usda_df[['year','county_name','state_ansi','county_ansi','Value']]\n",
    "\n",
    "    # We will change the datatype of year to datetime because it fits the data and we can have access to date functions\n",
    "    filtered_df.loc[:,'year'] = pd.to_datetime(filtered_df['year'],\n",
    "               format='%Y')\n",
    "    \n",
    "    # We need to ensure the start_year is a year too.\n",
    "    start_year = pd.to_datetime(str(start_year), format='%Y')\n",
    "\n",
    "    if end_year is not None:\n",
    "        end_year = pd.to_datetime(str(end_year), format='%Y')\n",
    "    else: end_year = start_year\n",
    "\n",
    "    # Filter starting from the requested year\n",
    "    filtered_df = filtered_df[(filtered_df['year'] >= start_year) & (filtered_df['year'] <= end_year)]\n",
    "   \n",
    "    # Remove the \"Other\" type county entries. We convert to all caps to handle any inconsistencies\n",
    "    if other == 'Yes':\n",
    "        filtered_df = filtered_df[~filtered_df['county_name'].str.upper().str.contains('OTHER')]\n",
    "    \n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try out the new function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usda_subset = clean_usda(usda,1950,2024,)\n",
    "usda_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a cool looking graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "# Create the plot\n",
    "ax = sns.histplot(data=usda_subset, x=\"Value\", hue=\"county_name\", multiple=\"stack\", palette=\"tab20\")\n",
    "\n",
    "plt.xlabel('BU/Acre')\n",
    "plt.title('Bushels/Acre by County for Past 7 Decades')\n",
    "\n",
    "# Manually create the legend with the right colors from the palette\n",
    "# Get the palette used for the plot\n",
    "palette = sns.color_palette(\"tab20\", n_colors=usda_subset['county_name'].nunique())\n",
    "\n",
    "# Get unique counties and map them to the corresponding palette color\n",
    "handles = [mpatches.Patch(color=palette[i], label=county) \n",
    "           for i, county in enumerate(usda_subset['county_name'].unique())]\n",
    "\n",
    "# Add the legend outside the plot\n",
    "ax.legend(handles=handles, bbox_to_anchor=(1.05, 1), loc='upper left', \n",
    "          borderaxespad=0, ncol=2, fontsize='small')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GDD calculation function\n",
    "def calculate_gdd(df, base_temp=50, upper_temp=86):\n",
    "    \"\"\"\n",
    "    Calculate Growing Degree Days (GDD) for corn.\n",
    "    \"\"\"\n",
    "    df['TMAX'] = df['TMAX'].clip(lower=base_temp, upper=upper_temp)\n",
    "    df['TMIN'] = df['TMIN'].clip(lower=base_temp)\n",
    "    df['TAVG'] = (df['TMAX'] + df['TMIN']) / 2\n",
    "    df['GDD'] = df['TAVG'] - base_temp\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = calculate_gdd(weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare average yield for usda_data_1955 and usda_data_2015\n",
    "usda_1955 = clean_usda(usda,1955,None,)\n",
    "usda_2015 = clean_usda(usda,2015,None,)\n",
    "\n",
    "usda_1955['Value'].mean(), usda_2015['Value'].mean()\n",
    "\n",
    "# whats the std deviation of yield for those years\n",
    "usda_1955['Value'].std(), usda_2015['Value'].std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare total gdd for weather_data_1955 and weather_data_2015 for county_ansi=161\n",
    "weather_2014 = pd.read_csv('data/weather_data_2014.csv')\n",
    "weather_2023 = pd.read_csv('data/weather_data_2023.csv')\n",
    "\n",
    "weather_2014 = calculate_gdd(weather_2014)\n",
    "weather_2023 = calculate_gdd(weather_2023)\n",
    "\n",
    "weather_2014[weather_2014['county_ansi'] == 161]['GDD'].sum(), weather_2023[weather_2023['county_ansi'] == 161]['GDD'].sum()\n",
    "\n",
    "# Do this for all years between 1950 and 1959\n",
    "gdd = []\n",
    "for year in range(1950, 1960):\n",
    "    weather = pd.read_csv(f'data/weather_data_{year}.csv')\n",
    "    weather = calculate_gdd(weather)\n",
    "    gdd.append(weather[weather['county_ansi'] == 161]['GDD'].sum())\n",
    "\n",
    "gdd\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
